# OpenLLM: Open Source Large Language Model

<!-- Copyright (C) 2024 Louis Chua Bean Chong -->
<!-- This file is part of OpenLLM - dual-licensed under GPLv3 and Commercial License -->

## ğŸŒŸ Overview

OpenLLM is an open source project to develop a powerful, flexible, and modular large language model (LLM) that is openly licensed under GPLv3 for research and community use, with a commercial license available for enterprise applications.

## ğŸš€ Key Features

- âœ”ï¸ Pretraining and fine-tuning pipeline
- âœ”ï¸ Tokenizer training with SentencePiece or BPE
- âœ”ï¸ Support for multilingual datasets
- âœ”ï¸ Transformer-based architecture (GPT-like)
- âœ”ï¸ Model quantization and export for inference
- âœ”ï¸ Integration with Hugging Face, PyTorch, and ONNX
- âœ”ï¸ CLI and RESTful API for inference
- ğŸ”’ Enterprise: RLHF trainer, fine-tuning UI, inference server orchestration (Kubernetes)

## ğŸ§  Design Goals

- Fully transparent and reproducible LLM stack
- Plug-and-play components (tokenizer, model, trainer)
- Scalable to billions of parameters
- Simple to extend with downstream tasks

## ğŸ“‚ Folder Structure

```
osllm-1/
â”œâ”€â”€ core/             # Open source components (training, tokenization, inference)
â”‚   â””â”€â”€ src/          # Python source files
â”‚       â”œâ”€â”€ download_and_prepare.py    # SQUAD dataset downloader & processor
â”‚       â””â”€â”€ train_tokenizer.py         # SentencePiece tokenizer trainer
â”œâ”€â”€ data/             # Training data and model artifacts
â”‚   â”œâ”€â”€ raw/          # Downloaded raw data (temporary)
â”‚   â”œâ”€â”€ clean/        # Processed training text
â”‚   â”‚   â””â”€â”€ training_data.txt          # ~41k Wikipedia passages from SQUAD
â”‚   â””â”€â”€ tokenizer/    # Trained tokenizer files
â”œâ”€â”€ enterprise/       # Enterprise-only modules (e.g., dashboard, RLHF UI)
â”œâ”€â”€ docs/             # Documentation and community guidelines
â”‚   â””â”€â”€ training_pipeline.md           # Complete training guide
â””â”€â”€ .github/          # GitHub config (PR template, funding, etc.)
```

## ğŸ› ï¸ Tech Stack

- Python 3.10+
- PyTorch
- Hugging Face Transformers
- SentencePiece
- FastAPI for inference API

## ğŸ’¼ Licensing

OpenLLM is **dual-licensed** to provide maximum flexibility:

### ğŸ†“ GPLv3 (Free for Open Source)
- âœ… **Perfect for:** Research, education, open source projects
- âœ… **Free to use** and modify
- âš ï¸ **Requirement:** Share modifications under GPL

### ğŸ’¼ Commercial License
- âœ… **Perfect for:** Proprietary software, SaaS, enterprise
- âœ… **No copyleft** restrictions
- âœ… **Keep modifications private**
- âœ… **Enterprise support included**

**Quick Guide:**
- **Open source project?** â†’ Use GPLv3 (free)
- **Commercial product?** â†’ Get commercial license
- **Not sure?** â†’ Start with GPLv3, upgrade later

**License Files:**
- [`LICENSE`](LICENSE) - GPL-3.0 license text (GitHub recognized)
- [`LICENSE-COMMERCIAL`](LICENSE-COMMERCIAL) - Commercial license terms
- [`docs/LICENSES.md`](docs/LICENSES.md) - Complete dual licensing guide

ğŸ’¬ **Commercial licensing:** Contact us at [louischua@gmail.com]
