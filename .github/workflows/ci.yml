name: 🚀 CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.10"

jobs:
  # File Validation - NEW: Pre-flight checks
  validate:
    name: 🔍 File Validation
    runs-on: ubuntu-latest
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔍 Validate required files
        run: |
          echo "🔍 Validating required files..."
          
          # Core files
          test -f README.md || (echo "❌ README.md missing" && exit 1)
          test -f requirements.txt || (echo "❌ requirements.txt missing" && exit 1)
          
          # Workflow files
          test -f .github/workflows/ci.yml || (echo "❌ ci.yml missing" && exit 1)
          test -f .github/workflows/deploy-to-space.yml || (echo "❌ deploy-to-space.yml missing" && exit 1)
          
          # Core functionality files (if they exist)
          if [ -f "app.py" ]; then
            echo "✅ app.py found"
          else
            echo "⚠️ app.py not found (optional for core pipeline)"
          fi
          
          if [ -f "space_auth_test.py" ]; then
            echo "✅ space_auth_test.py found"
          else
            echo "⚠️ space_auth_test.py not found (optional for core pipeline)"
          fi
          
          echo "✅ File validation completed"

      - name: 📦 Validate dependencies
        run: |
          echo "🔍 Validating dependencies..."
          
          # Check if requirements.txt has content
          if [ ! -s requirements.txt ]; then
            echo "❌ requirements.txt is empty"
            exit 1
          fi
          
          # Check for pinned versions (recommended)
          echo "📋 Checking dependency versions..."
          grep -E "^[a-zA-Z0-9_-]+==" requirements.txt || echo "⚠️ Some dependencies may not be pinned"
          
          echo "✅ Dependency validation completed"

  # Code Quality Checks
  lint:
    name: 🧹 Code Quality
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Pin exact versions for reproducible builds
          pip install black==23.12.1 isort==5.13.2 flake8==7.0.0 mypy==1.8.0
          pip install -r requirements.txt

      - name: 🎨 Check code formatting (Black)
        run: |
          black --check --diff core/ || echo "⚠️ Code formatting issues found"
        continue-on-error: true

      - name: 📚 Check import sorting (isort)
        run: |
          isort --check-only --diff core/ || echo "⚠️ Import sorting issues found"
        continue-on-error: true

      - name: 🔍 Lint code (flake8)
        run: |
          flake8 core/ --max-line-length=100 --extend-ignore=E203,W503 || echo "⚠️ Linting issues found"
        continue-on-error: true

      - name: 🔧 Type checking (mypy)
        run: |
          mypy core/ --ignore-missing-imports || echo "⚠️ Type checking issues found"
        continue-on-error: true

  # Security Checks
  security:
    name: 🔒 Security Scan
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: 🛡️ Run security scan (bandit)
        run: |
          pip install bandit[toml]==1.7.5
          bandit -r core/ -f json -o bandit-report.json || echo "⚠️ Security issues found"
        continue-on-error: true

      - name: 📊 Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: bandit-report.json
          if-no-files-found: warn

  # Dependency Checks
  dependencies:
    name: 📦 Dependency Check
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: 🔍 Check for dependency vulnerabilities
        run: |
          pip install safety==2.3.5
          safety check --json --output safety-report.json || echo "⚠️ Dependency vulnerabilities found"
        continue-on-error: true

      - name: 📊 Upload dependency scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: dependency-scan-results
          path: safety-report.json
          if-no-files-found: warn

  # Multi-platform Testing
  test:
    name: 🧪 Test Suite
    runs-on: ${{ matrix.os }}
    needs: [validate]
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.8", "3.9", "3.10", "3.11", "3.12"]
        exclude:
          # Reduce matrix size by excluding some combinations
          - os: windows-latest
            python-version: "3.8"
          - os: macos-latest
            python-version: "3.8"

    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Pin testing dependencies
          pip install pytest==7.4.3 pytest-cov==4.1.0
          pip install -r requirements.txt

      - name: 🧪 Run simple tests (Unix)
        if: runner.os != 'Windows'
        run: |
          # Run simple tests first (no project imports)
          echo "🔍 Running simple tests on Unix..."
          python -c "import sys; print(f'Python version: {sys.version}')"
          python -c "import os; print(f'Current directory: {os.getcwd()}')"
          python -c "import os; print(f'Files in directory: {os.listdir(\".\")}')"
          python -m pytest tests/test_simple.py -v --tb=short
        continue-on-error: false

      - name: 🧪 Run simple tests (Windows)
        if: runner.os == 'Windows'
        shell: cmd
        run: |
          # Run simple tests first (no project imports)
          echo "🔍 Running simple tests on Windows..."
          python -c "import sys; print(f'Python version: {sys.version}')"
          python -c "import os; print(f'Current directory: {os.getcwd()}')"
          python -c "import os; print(f'Files in directory: {os.listdir(\".\")}')"
          python -m pytest tests/test_simple.py -v --tb=short
        continue-on-error: false

      - name: 🧪 Run basic tests (Unix)
        if: runner.os != 'Windows'
        run: |
          # Run basic tests (with project imports)
          python -m pytest tests/test_basic.py -v
        continue-on-error: true

      - name: 🧪 Run basic tests (Windows)
        if: runner.os == 'Windows'
        shell: cmd
        run: |
          # Run basic tests (with project imports)
          python -m pytest tests/test_basic.py -v
        continue-on-error: true

      - name: 🧪 Run full unit tests (Unix)
        if: runner.os != 'Windows'
        run: |
          # Debug: Show current directory and files
          echo "Current directory: $(pwd)"
          ls -la
          echo "Core src directory:"
          ls -la core/src/
          
          # Set up Python path for tests
          export PYTHONPATH="${PYTHONPATH}:${GITHUB_WORKSPACE}/core/src"
          echo "PYTHONPATH: $PYTHONPATH"
          
          # Test basic imports first
          python -c "import sys; print('Python path:'); [print(p) for p in sys.path]"
          python -c "import sys; sys.path.insert(0, '${GITHUB_WORKSPACE}/core/src'); import model; print('✅ Model import successful')" || echo "❌ Model import failed"
          
          # Run tests with better error handling
          python -m pytest tests/ -v --cov=core --cov-report=xml --cov-report=term-missing --tb=short || echo "⚠️ Some tests failed"
        continue-on-error: true

      - name: 🧪 Run full unit tests (Windows)
        if: runner.os == 'Windows'
        shell: cmd
        run: |
          # Debug: Show current directory and files
          echo "Current directory: %CD%"
          dir
          echo "Core src directory:"
          dir core\src
          
          # Set up Python path for tests
          set PYTHONPATH=%PYTHONPATH%;%GITHUB_WORKSPACE%\core\src
          echo "PYTHONPATH: %PYTHONPATH%"
          
          # Test basic imports first
          python -c "import sys; print('Python path:'); [print(p) for p in sys.path]"
          python -c "import sys; sys.path.insert(0, r'%GITHUB_WORKSPACE%\core\src'); import model; print('✅ Model import successful')" || echo "❌ Model import failed"
          
          # Run tests with better error handling
          python -m pytest tests/ -v --cov=core --cov-report=xml --cov-report=term-missing --tb=short || echo "⚠️ Some tests failed"
        continue-on-error: true

      - name: 📊 Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.10'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

  # Integration Tests
  integration:
    name: 🔗 Integration Tests
    runs-on: ubuntu-latest
    needs: [validate, lint]
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: 🔧 Test CLI help commands
        run: |
          # Test main CLI if it exists
          if [ -f "core/src/main.py" ]; then
            python core/src/main.py --help || echo "⚠️ Main CLI help failed"
            python core/src/main.py prepare-data --help || echo "⚠️ Prepare-data help failed"
            python core/src/main.py train-tokenizer --help || echo "⚠️ Train-tokenizer help failed"
          else
            echo "ℹ️ Main CLI not found, skipping CLI tests"
          fi
        continue-on-error: true

      - name: 📊 Test data preparation (small sample)
        run: |
          # Create a small test file
          mkdir -p data/clean
          echo "This is a test sentence with more than ten words for testing." > data/clean/test_data.txt
          echo "Another test sentence to ensure we have enough content for testing purposes." >> data/clean/test_data.txt
          
          # Test that our file exists and has content
          wc -l data/clean/test_data.txt
          cat data/clean/test_data.txt
        continue-on-error: true

      - name: 🔤 Test tokenizer training (small vocab)
        run: |
          # Only run if main.py exists
          if [ -f "core/src/main.py" ]; then
            # Train a very small tokenizer for testing
            python core/src/main.py train-tokenizer \
              --input data/clean/test_data.txt \
              --vocab-size 100 \
              --output-dir data/test_tokenizer/ \
              --no-test || echo "⚠️ Tokenizer training failed"
            
            # Verify tokenizer files were created
            ls -la data/test_tokenizer/ || echo "⚠️ Tokenizer directory not found"
            test -f data/test_tokenizer/tokenizer.model || echo "⚠️ Tokenizer model not found"
            test -f data/test_tokenizer/tokenizer.vocab || echo "⚠️ Tokenizer vocab not found"
          else
            echo "ℹ️ Main CLI not found, skipping tokenizer tests"
          fi
        continue-on-error: true

      - name: 🧹 Cleanup test files
        if: always()
        run: |
          rm -rf data/clean/test_data.txt
          rm -rf data/test_tokenizer/

  # Documentation checks
  docs:
    name: 📚 Documentation
    runs-on: ubuntu-latest
    needs: [validate]
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔍 Check for broken links
        run: |
          # Install markdown link checker
          npm install -g markdown-link-check@3.10.3
          
          # Check all markdown files for broken links
          find . -name "*.md" -not -path "./venv/*" -not -path "./.git/*" \
            -exec markdown-link-check {} \; || echo "⚠️ Some broken links found"
        continue-on-error: true

      - name: 📏 Check documentation completeness
        run: |
          # Check that key documentation files exist
          test -f README.md || echo "⚠️ README.md missing"
          
          # Check CLI help if main.py exists
          if [ -f "core/src/main.py" ]; then
            python core/src/main.py --help | grep -q "OpenLLM" || echo "⚠️ Main CLI help incomplete"
            python core/src/main.py prepare-data --help | grep -q "Download and prepare" || echo "⚠️ Prepare-data help incomplete"
            python core/src/main.py train-tokenizer --help | grep -q "Train a SentencePiece" || echo "⚠️ Train-tokenizer help incomplete"
          else
            echo "ℹ️ Main CLI not found, skipping CLI help checks"
          fi
        continue-on-error: true

  # Performance benchmarks
  benchmark:
    name: ⚡ Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [validate]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: 📦 Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install psutil==5.9.6 memory-profiler==0.61.0

      - name: ⏱️ Benchmark CLI startup time
        run: |
          echo "Measuring CLI startup time..."
          if [ -f "core/src/main.py" ]; then
            time python core/src/main.py --help > /dev/null || echo "⚠️ CLI startup failed"
          else
            echo "ℹ️ Main CLI not found, skipping startup benchmark"
          fi
        continue-on-error: true

      - name: 💾 Check memory usage
        run: |
          echo "Checking memory usage..."
          if [ -f "core/src/main.py" ]; then
            python -c "
            import psutil
            import subprocess
            import sys
            
            # Get memory before
            process = psutil.Process()
            mem_before = process.memory_info().rss / 1024 / 1024
            
            # Run a simple command
            result = subprocess.run([sys.executable, 'core/src/main.py', '--help'], 
                                capture_output=True, text=True)
            
            # Get memory after
            mem_after = process.memory_info().rss / 1024 / 1024
            
            print(f'Memory usage: {mem_after:.1f} MB')
            print(f'Memory change: {mem_after - mem_before:.1f} MB')
            " || echo "⚠️ Memory check failed"
          else
            echo "ℹ️ Main CLI not found, skipping memory check"
          fi
        continue-on-error: true

  # Release preparation (only on main branch)
  release-check:
    name: 🏷️ Release Check
    runs-on: ubuntu-latest
    needs: [validate, lint, test, integration, docs]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: 📥 Checkout code
        uses: actions/checkout@v4

      - name: 🔍 Check version consistency
        run: |
          # Check that versions are consistent across files
          if [ -f "pyproject.toml" ]; then
            grep -q "version.*0\.1\.0" pyproject.toml || echo "⚠️ Version mismatch in pyproject.toml"
          fi
          
          if [ -f "core/src/main.py" ]; then
            grep -q "OpenLLM v0\.1\.0" core/src/main.py || echo "⚠️ Version mismatch in main.py"
          fi
        continue-on-error: true

      - name: 📋 Check changelog
        run: |
          # Check if CHANGELOG.md exists (will be created later)
          test -f CHANGELOG.md || echo "ℹ️ CHANGELOG.md not found (will be created in future)"
        continue-on-error: true

  # All checks passed
  all-checks:
    name: ✅ All Checks Passed
    runs-on: ubuntu-latest
    needs: [validate, lint, security, dependencies, test, integration, docs]
    if: always()
    steps:
      - name: 🎉 All checks completed
        run: |
          echo "All CI/CD checks have completed!"
          echo "Status summary:"
          echo "- Validation: ${{ needs.validate.result }}"
          echo "- Linting: ${{ needs.lint.result }}"
          echo "- Security: ${{ needs.security.result }}"
          echo "- Dependencies: ${{ needs.dependencies.result }}"
          echo "- Tests: ${{ needs.test.result }}"
          echo "- Integration: ${{ needs.integration.result }}"
          echo "- Documentation: ${{ needs.docs.result }}"

      - name: ❌ Fail if critical checks failed
        if: |
          needs.validate.result == 'failure' ||
          needs.lint.result == 'failure' ||
          needs.test.result == 'failure'
        run: |
          echo "🚨 CRITICAL CHECKS FAILED!"
          echo "=================================="
          echo "The following critical checks failed:"
          echo "- Validation: ${{ needs.validate.result }}"
          echo "- Linting: ${{ needs.lint.result }}"
          echo "- Tests: ${{ needs.test.result }}"
          echo ""
          echo "🔧 REQUIRED ACTIONS:"
          echo "1. Fix validation issues (missing files, dependencies)"
          echo "2. Fix linting issues (code formatting, imports)"
          echo "3. Fix test failures (especially simple tests)"
          echo ""
          echo "❌ Workflow cannot proceed until these issues are resolved."
          exit 1

      - name: ⚠️ Warn about non-critical failures
        if: |
          needs.security.result == 'failure' ||
          needs.dependencies.result == 'failure' ||
          needs.integration.result == 'failure' ||
          needs.docs.result == 'failure'
        run: |
          echo "⚠️ Some non-critical checks failed. Please review:"
          echo "- Security scan results"
          echo "- Dependency vulnerabilities"
          echo "- Integration test issues"
          echo "- Documentation problems"