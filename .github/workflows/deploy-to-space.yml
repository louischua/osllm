name: Deploy to Hugging Face Spaces

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:

jobs:
  # Pre-deployment validation
  validate-deployment:
    name: üîç Validate Deployment Files
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
      
    - name: Validate required files
      run: |
        echo "üîç Validating files for deployment..."
        
        # Required files for Inference Space deployment
        inference_files=(
          "llm/app.py"
          "llm/requirements.txt"
        )
        
        # Required files for Training Space deployment
        training_files=(
          "training_space/app.py"
          "training_space/requirements.txt"
          "training_space/README.md"
        )
        
        # Optional files (warn if missing)
        optional_files=(
          "space_auth_test.py"
          "openllm_training_with_auth.py"
          "integrate_auth_into_training.py"
          "setup_hf_space_auth.py"
          "verify_space_auth.py"
        )
        
        missing_inference=()
        missing_training=()
        missing_optional=()
        
        echo "üìã Checking Inference Space files..."
        for file in "${inference_files[@]}"; do
          if [ ! -f "$file" ]; then
            missing_inference+=("$file")
          else
            echo "‚úÖ $file found"
          fi
        done
        
        echo "üìã Checking Training Space files..."
        for file in "${training_files[@]}"; do
          if [ ! -f "$file" ]; then
            missing_training+=("$file")
          else
            echo "‚úÖ $file found"
          fi
        done
        
        for file in "${optional_files[@]}"; do
          if [ ! -f "$file" ]; then
            missing_optional+=("$file")
          else
            echo "‚úÖ $file found"
          fi
        done
        
        if [ ${#missing_inference[@]} -ne 0 ]; then
          echo "‚ùå Missing inference space files:"
          printf '  - %s\n' "${missing_inference[@]}"
          exit 1
        fi
        
        if [ ${#missing_training[@]} -ne 0 ]; then
          echo "‚ùå Missing training space files:"
          printf '  - %s\n' "${missing_training[@]}"
          exit 1
        fi
        
        if [ ${#missing_optional[@]} -ne 0 ]; then
          echo "‚ö†Ô∏è Missing optional files:"
          printf '  - %s\n' "${missing_optional[@]}"
        fi
        
        echo "‚úÖ All required files present"
        
    - name: Install dependencies for validation
      run: |
        echo "üì¶ Installing dependencies for validation..."
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Validate file contents
      run: |
        echo "üîç Validating file contents..."
        
        # Debug: Show current directory and files
        echo "Current directory: $(pwd)"
        echo "Files in current directory:"
        ls -la
        
        # Check inference space files
        echo "üîç Validating Inference Space files..."
        for file in llm/app.py llm/requirements.txt; do
          if [ ! -f "$file" ]; then
            echo "‚ùå $file not found"
            exit 1
          elif [ ! -s "$file" ]; then
            echo "‚ùå $file is empty"
            exit 1
          else
            echo "‚úÖ $file has content ($(wc -c < "$file") bytes)"
          fi
        done
        
        # Check training space files
        echo "üîç Validating Training Space files..."
        for file in training_space/app.py training_space/requirements.txt training_space/README.md; do
          if [ ! -f "$file" ]; then
            echo "‚ùå $file not found"
            exit 1
          elif [ ! -s "$file" ]; then
            echo "‚ùå $file is empty"
            exit 1
          else
            echo "‚úÖ $file has content ($(wc -c < "$file") bytes)"
          fi
        done
        
        # Simple Python syntax check
        echo "üîç Validating Python syntax..."
        python --version
        
        # Validate inference space app
        python -c "import sys; sys.path.append('llm'); import app"
        
        # Validate training space app
        python -c "import sys; sys.path.append('training_space'); import app"
        
        # Check optional files if they exist
        if [ -f "space_auth_test.py" ]; then
          python -c "import space_auth_test"
        fi
        
        if [ -f "openllm_training_with_auth.py" ]; then
          python -c "import openllm_training_with_auth"
        fi
        
        echo "‚úÖ File validation completed"

  deploy-inference-space:
    name: üöÄ Deploy Inference Space (lemms/llm)
    runs-on: ubuntu-latest
    needs: [validate-deployment]
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install huggingface_hub==0.19.0
        
    - name: Deploy files to Inference Space
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        SPACE_ID: ${{ secrets.SPACE_ID }}
      run: |
        echo "üöÄ Deploying to Inference Space (lemms/llm)..."
        
        # Function to deploy a file
        deploy_file() {
          local file_path="$1"
          local space_path="$2"
          
          if [ ! -f "$file_path" ]; then
            echo "‚ö†Ô∏è File not found: $file_path"
            return 1
          fi
          
          echo "üì§ Deploying $file_path to $space_path"
          
          python -c "
        import os
        from huggingface_hub import HfApi
        
        api = HfApi()
        token = os.environ.get('HF_TOKEN')
        space_id = os.environ.get('SPACE_ID')
        
        if not token:
            print('‚ùå HF_TOKEN not found')
            exit(1)
            
        if not space_id:
            print('‚ùå SPACE_ID not found')
            exit(1)
            
        try:
            api.upload_file(
                path_or_fileobj='$file_path',
                path_in_repo='$space_path',
                repo_id=space_id,
                repo_type='space',
                token=token
            )
            print(f'‚úÖ Successfully uploaded $file_path to $space_path')
        except Exception as e:
            print(f'‚ùå Failed to upload $file_path: {e}')
            exit(1)
        "
        }
        
        # Deploy inference space files
        deploy_file "llm/app.py" "app.py"
        deploy_file "llm/requirements.txt" "requirements.txt"
        
        echo "‚úÖ Inference Space deployment completed"

  deploy-training-space:
    name: üöÄ Deploy Training Space (lemms/openllm)
    runs-on: ubuntu-latest
    needs: [validate-deployment]
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install huggingface_hub==0.19.0
        
    - name: Deploy files to Training Space
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üöÄ Deploying to Training Space (lemms/openllm)..."
        
        # Function to deploy a file
        deploy_file() {
          local file_path="$1"
          local space_path="$2"
          
          if [ ! -f "$file_path" ]; then
            echo "‚ö†Ô∏è File not found: $file_path"
            return 1
          fi
          
          echo "üì§ Deploying $file_path to $space_path"
          
          python -c "
        import os
        from huggingface_hub import HfApi
        
        api = HfApi()
        token = os.environ.get('HF_TOKEN')
        space_id = 'lemms/openllm'  # Hardcoded training space ID
        
        if not token:
            print('‚ùå HF_TOKEN not found')
            exit(1)
            
        try:
            api.upload_file(
                path_or_fileobj='$file_path',
                path_in_repo='$space_path',
                repo_id=space_id,
                repo_type='space',
                token=token
            )
            print(f'‚úÖ Successfully uploaded $file_path to $space_path')
        except Exception as e:
            print(f'‚ùå Failed to upload $file_path: {e}')
            exit(1)
        "
        }
        
        # Deploy training space files
        deploy_file "training_space/app.py" "app.py"
        deploy_file "training_space/requirements.txt" "requirements.txt"
        deploy_file "training_space/README.md" "README.md"
        
        echo "‚úÖ Training Space deployment completed"

  verify-deployment:
    name: üîç Verify Deployment
    runs-on: ubuntu-latest
    needs: [deploy-inference-space, deploy-training-space]
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install huggingface_hub==0.19.0
        
    - name: Verify Inference Space deployment
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        SPACE_ID: ${{ secrets.SPACE_ID }}
      run: |
        echo "üîç Verifying Inference Space deployment..."
        
        python -c "
        import os
        from huggingface_hub import HfApi
        
        api = HfApi()
        token = os.environ.get('HF_TOKEN')
        space_id = os.environ.get('SPACE_ID')
        
        if not token or not space_id:
            print('‚ùå Missing HF_TOKEN or SPACE_ID')
            exit(1)
            
        try:
            files = api.list_repo_files(space_id, repo_type='space', token=token)
            print('üìÅ Files in Inference Space:')
            for file in files:
                print(f'  - {file}')
                
            required_files = ['app.py', 'requirements.txt']
            deployed_files = [f for f in files if f in required_files]
            
            if len(deployed_files) == len(required_files):
                print('‚úÖ All required files deployed to Inference Space')
            else:
                print(f'‚ö†Ô∏è Missing files: {set(required_files) - set(deployed_files)}')
                exit(1)
                
        except Exception as e:
            print(f'‚ùå Failed to verify Inference Space: {e}')
            exit(1)
        "
        
    - name: Verify Training Space deployment
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
      run: |
        echo "üîç Verifying Training Space deployment..."
        
        python -c "
        import os
        from huggingface_hub import HfApi
        
        api = HfApi()
        token = os.environ.get('HF_TOKEN')
        space_id = 'lemms/openllm'  # Hardcoded training space ID
        
        if not token:
            print('‚ùå Missing HF_TOKEN')
            exit(1)
            
        try:
            files = api.list_repo_files(space_id, repo_type='space', token=token)
            print('üìÅ Files in Training Space:')
            for file in files:
                print(f'  - {file}')
                
            required_files = ['app.py', 'requirements.txt', 'README.md']
            deployed_files = [f for f in files if f in required_files]
            
            if len(deployed_files) == len(required_files):
                print('‚úÖ All required files deployed to Training Space')
            else:
                print(f'‚ö†Ô∏è Missing files: {set(required_files) - set(deployed_files)}')
                exit(1)
                
        except Exception as e:
            print(f'‚ùå Failed to verify Training Space: {e}')
            exit(1)
        "
        
    - name: Deployment Summary
      run: |
        echo "üéâ Deployment Summary"
        echo "=================="
        echo "‚úÖ Inference Space (lemms/llm): Deployed and verified"
        echo "‚úÖ Training Space (lemms/openllm): Deployed and verified"
        echo ""
        echo "üåê Spaces are available at:"
        echo "  - Inference: https://huggingface.co/spaces/lemms/llm"
        echo "  - Training: https://huggingface.co/spaces/lemms/openllm"
        echo ""
        echo "‚è≥ Spaces will take a few minutes to build and become available."
        
    - name: Rollback on failure
      if: failure()
      env:
        HF_TOKEN: ${{ secrets.HF_TOKEN }}
        SPACE_ID: ${{ secrets.SPACE_ID }}
      run: |
        echo "üîÑ Rolling back deployment due to failure..."
        echo "‚ö†Ô∏è Manual intervention may be required to restore the spaces"
