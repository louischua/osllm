name: üêõ Bug Report
description: File a bug report to help us improve OpenLLM
title: "[Bug]: "
labels: ["bug", "needs-triage"]
assignees: []

body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to fill out this bug report! üôè
        
        Please provide as much detail as possible to help us understand and reproduce the issue.

  - type: checkboxes
    id: existing-issues
    attributes:
      label: Existing Issues
      description: Please search existing issues before creating a new one
      options:
        - label: I have searched existing issues and this is not a duplicate
          required: true

  - type: dropdown
    id: component
    attributes:
      label: Component
      description: Which component is affected by this bug?
      options:
        - Data preparation (download_and_prepare.py)
        - Tokenizer training (train_tokenizer.py)
        - CLI interface (main.py)
        - Documentation
        - Installation/Setup
        - Other
    validations:
      required: true

  - type: textarea
    id: description
    attributes:
      label: Bug Description
      description: A clear and concise description of what the bug is
      placeholder: Describe what happened vs what you expected to happen
    validations:
      required: true

  - type: textarea
    id: reproduction
    attributes:
      label: Steps to Reproduce
      description: Step-by-step instructions to reproduce the bug
      placeholder: |
        1. Run command: `python core/src/main.py prepare-data`
        2. See error message: ...
        3. ...
    validations:
      required: true

  - type: textarea
    id: expected
    attributes:
      label: Expected Behavior
      description: What did you expect to happen?
      placeholder: Describe the expected outcome
    validations:
      required: true

  - type: textarea
    id: actual
    attributes:
      label: Actual Behavior
      description: What actually happened?
      placeholder: Describe what actually occurred, including any error messages
    validations:
      required: true

  - type: textarea
    id: environment
    attributes:
      label: Environment
      description: Please provide information about your environment
      placeholder: |
        - OS: [e.g., Ubuntu 22.04, macOS 13.0, Windows 11]
        - Python version: [e.g., 3.10.5]
        - PyTorch version: [e.g., 2.0.1]
        - GPU: [e.g., NVIDIA RTX 4090, Apple M2, None]
        - RAM: [e.g., 32GB]
        - OpenLLM version: [e.g., v0.1.0, commit hash]
    validations:
      required: true

  - type: textarea
    id: error-logs
    attributes:
      label: Error Logs
      description: Please include any relevant error logs or stack traces
      placeholder: |
        ```
        Paste error logs here
        ```
    validations:
      required: false

  - type: textarea
    id: additional-context
    attributes:
      label: Additional Context
      description: Add any other context about the problem here
      placeholder: |
        - Screenshots
        - Related issues
        - Workarounds you've tried
        - etc.
    validations:
      required: false

  - type: checkboxes
    id: contribution
    attributes:
      label: Contribution
      description: Are you willing to contribute a fix?
      options:
        - label: I'm willing to help fix this issue
          required: false