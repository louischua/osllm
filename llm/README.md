---
title: OpenLLM Inference Space
emoji: üöÄ
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: 4.44.1
app_file: app.py
pinned: false
license: gpl-3.0
---

# üöÄ OpenLLM Inference Space - Interactive AI Model Demo

## üìö What is This Space?

Welcome to the **OpenLLM Inference Space**! This is an interactive web application where you can experiment with different AI language models that we've trained from scratch. Think of it as a "playground" where you can see how AI models learn and improve over time.

**Note**: This space is specifically for **model inference and comparison**. For live model training, visit our **[Training Space](https://huggingface.co/spaces/lemms/openllm)**.

### üéØ What Makes This Special?

Unlike most AI demos that use models from big companies, **all the models here were trained by us using our own OpenLLM framework**. This means:
- **Transparency**: You can see exactly how the models work
- **Educational**: Learn how AI models improve with more training
- **Open Source**: Everything is free and open for you to study
- **Comparable**: See the difference between models at different training stages

## üß† Understanding the Models

### What is a Language Model?

A language model is like a very smart autocomplete that has read millions of books and articles. When you give it some text, it tries to predict what should come next.

**Example:**
- **Your input**: "The weather today is..."
- **Model's prediction**: "sunny" or "rainy" or "cloudy"
- **What it's doing**: Using patterns it learned from reading lots of text about weather

### How Do These Models Work?

#### The Learning Process
1. **Reading Phase**: The model reads through millions of sentences from Wikipedia, books, and articles
2. **Pattern Recognition**: It learns that certain words often appear together
3. **Prediction Training**: It practices predicting the next word in sentences
4. **Improvement**: When it's wrong, it adjusts its "thinking" to do better next time

#### The Architecture
Our models use something called a **Transformer** architecture, which is like having multiple "attention heads" that can focus on different parts of a sentence:

```
Input: "The cat sat on the mat"
Attention Head 1: Focuses on "cat" and "sat" (action)
Attention Head 2: Focuses on "on" and "mat" (location)
Attention Head 3: Focuses on "the" (grammar)
```

## üìä Model Comparison - Understanding the Differences

We have **7 different models** trained for different amounts of time. This lets you see how AI models improve with more training:

### The Training Journey

| Model | Training Steps | What This Means | Best Loss | Perplexity | What You'll Notice |
|-------|---------------|-----------------|-----------|------------|-------------------|
| **4k Model** | 4,000 | Like a student who just started learning | ~6.2 | ~492 | Basic responses, sometimes confused |
| **6k Model** | 6,000 | Student who has studied for a few weeks | ~5.8 | ~816 | Better grammar, more coherent |
| **7k Model** | 7,000 | Student who has studied for a month | ~5.5 | ~8.2 | Good understanding, clear responses |
| **8k Model** | 8,000 | Student who has studied for two months | ~5.3 | ~200 | Sophisticated, detailed answers |
| **9k Model** | 9,000 | **Best student** - studied the most | ~5.2 | ~177 | **Highest quality responses** |
| **10k Model** | 10,000 | Extended training, maintained quality | ~5.22 | ~184 | Similar to 9k, slightly different |
| **10k Improved** | 10,000 | Same training, better process | ~5.1774 | ~177 | **Latest and greatest** |

### Understanding the Metrics

#### Loss (Lower is Better)
- **What it measures**: How often the model makes mistakes
- **4k Model (6.2)**: Makes more mistakes, like a beginner
- **9k Model (5.2)**: Makes fewer mistakes, like an expert
- **Think of it like**: A test score - lower means fewer wrong answers

#### Perplexity (Lower is Better)
- **What it measures**: How confident the model is in its predictions
- **High perplexity (492)**: Model is often surprised by what comes next
- **Low perplexity (177)**: Model is very confident in its predictions
- **Think of it like**: How well you can predict the next word in a story

## üéÆ How to Use This Space

### Step-by-Step Guide

#### 1. Select a Model
- **Dropdown Menu**: Choose from the 7 available models
- **Start with 4k**: See how a basic model performs
- **Try 9k**: See the best performing model
- **Compare**: Switch between models to see differences

#### 2. Enter Your Prompt
- **Text Box**: Type what you want the AI to respond to
- **Examples**:
  - "Explain quantum physics"
  - "Write a short story about a robot"
  - "What are the benefits of renewable energy?"
  - "How do computers work?"

#### 3. Adjust Parameters
- **Temperature**: Controls creativity
  - **Low (0.1-0.5)**: More predictable, factual responses
  - **High (0.7-1.0)**: More creative, varied responses
- **Max Length**: How long the response should be
  - **Short (50-100)**: Quick answers
  - **Long (200-500)**: Detailed explanations
- **Top-K**: Limits word choices (higher = more variety)
- **Top-P**: Nucleus sampling (controls randomness)

#### 4. Generate Text
- **Click "Generate"**: Watch the AI create text
- **Wait**: Generation takes a few seconds
- **Read**: See how the model responds

### Pro Tips for Better Results

#### Writing Good Prompts
- **Be Specific**: "Explain photosynthesis" vs "Tell me about plants"
- **Set Context**: "Write a children's story about..." vs "Write about..."
- **Ask for Format**: "List 5 benefits of..." vs "What are the benefits of..."

#### Understanding Model Differences
- **4k-6k Models**: Good for simple questions, basic explanations
- **7k-8k Models**: Better for detailed explanations, longer responses
- **9k-10k Models**: Best for complex topics, creative writing, technical explanations

## üî¨ Educational Experiments You Can Try

### Experiment 1: Model Comparison
**Goal**: See how training affects model quality

**Steps**:
1. Use the same prompt with different models
2. Compare the quality, length, and coherence
3. Notice how 9k model gives better answers than 4k

**Example Prompt**: "Explain how photosynthesis works"

### Experiment 2: Parameter Tuning
**Goal**: Understand how settings affect output

**Steps**:
1. Use the same model and prompt
2. Try different temperature settings
3. Notice how creativity changes

**Example**: 
- Temperature 0.1: Factual, consistent
- Temperature 0.9: Creative, varied

### Experiment 3: Prompt Engineering
**Goal**: Learn how to get better results

**Steps**:
1. Try vague prompts vs specific prompts
2. Test different question formats
3. See which prompts work best

**Examples**:
- Vague: "Tell me about space"
- Specific: "Explain the three main types of galaxies in simple terms"

## üß™ Technical Details for Students

### Model Architecture
- **Type**: GPT-style Transformer (decoder-only)
- **Size**: Small (35.8 million parameters)
- **Layers**: 6 transformer layers
- **Attention Heads**: 8 heads per layer
- **Embedding Dimension**: 512
- **Vocabulary**: 32,000 tokens (words/subwords)
- **Context Length**: 1,024 tokens (about 750 words)

### Training Data
- **Source**: Wikipedia passages from SQuAD dataset
- **Content**: Educational, factual information
- **Language**: English
- **Size**: Millions of sentences

### Training Process
- **Framework**: PyTorch
- **Optimizer**: Adam with learning rate 3e-4
- **Batch Size**: 4 (with gradient accumulation)
- **Sequence Length**: 512 tokens
- **Hardware**: GPU training for efficiency

## üéØ What You Can Learn From This

### AI/ML Concepts
- **Supervised Learning**: Models learn from examples
- **Neural Networks**: How AI "thinks"
- **Training vs Inference**: Learning vs using
- **Overfitting**: When models memorize instead of learning
- **Hyperparameters**: Settings that affect training

### Natural Language Processing
- **Tokenization**: Converting text to numbers
- **Embeddings**: Representing words as vectors
- **Attention**: Focusing on important parts of text
- **Language Modeling**: Predicting next words
- **Text Generation**: Creating coherent text

### Machine Learning Best Practices
- **Validation**: Testing on unseen data
- **Checkpointing**: Saving progress during training
- **Early Stopping**: Preventing overfitting
- **Hyperparameter Tuning**: Finding optimal settings
- **Model Evaluation**: Measuring performance

## üîç Understanding the Output

### What Makes Good AI Text?
- **Coherence**: Sentences flow logically
- **Relevance**: Answers the question asked
- **Accuracy**: Information is correct
- **Completeness**: Covers the topic adequately
- **Grammar**: Proper sentence structure

### Common Issues You Might See
- **Repetition**: Model repeats the same phrases
- **Hallucination**: Model makes up false information
- **Incoherence**: Sentences don't connect well
- **Bias**: Model reflects biases in training data
- **Limited Knowledge**: Model doesn't know recent events

### How to Evaluate Responses
- **Fact-check**: Verify information accuracy
- **Readability**: Is it easy to understand?
- **Completeness**: Does it answer the question?
- **Creativity**: Is it original and interesting?
- **Appropriateness**: Is it suitable for the context?

## üöÄ Advanced Features

### Model Loading
- **Dynamic Loading**: Models load when selected
- **Caching**: Models stay loaded for faster switching
- **Memory Management**: Efficient use of resources
- **Error Handling**: Graceful handling of issues

### Text Generation
- **Sampling**: Multiple strategies for word selection
- **Temperature Scaling**: Controls randomness
- **Top-K Filtering**: Limits word choices
- **Nucleus Sampling**: Dynamic vocabulary selection

### User Interface
- **Responsive Design**: Works on different screen sizes
- **Real-time Updates**: See generation progress
- **Parameter Controls**: Easy adjustment of settings
- **Model Information**: Details about each model

## üîí Safety and Ethics

### Responsible AI Use
- **Educational Purpose**: This space is for learning and research
- **Content Moderation**: Be mindful of generated content
- **Bias Awareness**: Models may reflect training data biases
- **Fact Verification**: Always verify important information

### Best Practices
- **Respectful Prompts**: Avoid harmful or inappropriate requests
- **Critical Thinking**: Don't trust AI output blindly
- **Learning Focus**: Use this to understand AI, not replace human judgment
- **Community Guidelines**: Follow Hugging Face community standards

## üìö Learning Resources

### For Beginners
- **AI Basics**: Start with understanding what AI is
- **Machine Learning**: Learn about how computers learn
- **Natural Language Processing**: Study how computers understand text
- **Python Programming**: Basic programming skills help

### For Intermediate Users
- **Transformer Architecture**: Deep dive into the model structure
- **PyTorch**: Learn the deep learning framework
- **Training Techniques**: Understand how models learn
- **Evaluation Metrics**: Learn how to measure model performance

### For Advanced Users
- **Attention Mechanisms**: Understand how models focus
- **Optimization**: Learn about training efficiency
- **Architecture Design**: Study model structure decisions
- **Research Papers**: Read the latest developments

## ü§ù Contributing and Feedback

### How to Help
- **Report Issues**: Found a bug? Let us know!
- **Suggest Improvements**: Have ideas for new features?
- **Share Experiments**: Tell us about your discoveries
- **Improve Documentation**: Help make explanations clearer

### Getting Involved
- **GitHub Repository**: https://github.com/louischua/openllm
- **Discussions**: Join conversations about the project
- **Issues**: Report problems or request features
- **Pull Requests**: Contribute code improvements

## üìû Support and Contact

### Getting Help
- **GitHub Issues**: For technical problems
- **Discussions**: For questions and ideas
- **Documentation**: Check the main project README
- **Community**: Ask other users for help

### Contact Information
- **Author**: Louis Chua Bean Chong
- **Email**: louischua@gmail.com
- **GitHub**: https://github.com/louischua/openllm
- **Project**: https://github.com/louischua/openllm

## üéâ Conclusion

This OpenLLM Inference Space is more than just a demo - it's a **learning laboratory** where you can:

- **Explore AI**: See how language models work in practice
- **Compare Models**: Understand how training affects performance
- **Experiment**: Try different prompts and settings
- **Learn**: Gain hands-on experience with AI technology
- **Contribute**: Help improve the project and documentation

Whether you're a student learning about AI, a researcher exploring language models, or just curious about how these systems work, this space provides a unique opportunity to interact with open-source AI models and understand the technology behind them.

**Start exploring, start learning, start experimenting! üöÄ**

---

*This space is powered by the OpenLLM framework, an open-source project dedicated to democratizing AI technology. Your feedback and contributions are welcome!*
